{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3kNVUVqEpcN"
   },
   "source": [
    "# TRABAJO PRÁCTICO Nº 1\n",
    "\n",
    "**Alumnos:**\n",
    "- Nahuel Arrieta\n",
    "- Lucas moyano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAWyqBbGFlVv"
   },
   "source": [
    "## Ejercicion N° 1: Modos de color en imagenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Z38mM26FpYW"
   },
   "source": [
    "### 1. Utilizando openCV en python, cargar una imagen RGB y mostrarla en una ventana utilizando el comando imread() y imshow(), tambien puede utilizar matplotlib para mostrarla.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LpYB6_B_W6bI"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GnNhSSrRW83Y"
   },
   "outputs": [],
   "source": [
    "def read_image(image_name):\n",
    "  image_path = \"./images/\" + image_name\n",
    "\n",
    "  # Read the image\n",
    "  image = cv2.imread(image_path)\n",
    "  if image is None:\n",
    "    sys.exit(\"Could not read the image \" + image_path)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JW9xMr69Fv7W"
   },
   "outputs": [],
   "source": [
    "def show_image(label, image):\n",
    "  # Show the image\n",
    "  print(label + \":\")\n",
    "  cv2_imshow(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "CHIXNYKtGU0L",
    "outputId": "07505c83-94b6-44a2-cb55-04c472e8b6ac"
   },
   "outputs": [],
   "source": [
    "image_name = \"mate.png\"\n",
    "\n",
    "\n",
    "image = read_image( image_name)\n",
    "show_image(\"Image\", image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qV2KTploG0Wy"
   },
   "source": [
    "### 2. Una vez cargada la imagen de muestra podemos empezar usando numpy y su función array para obtener el arreglo de valores de intensidad para cada uno de los canales de color.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1u-SDdm6G3KT",
    "outputId": "3ff6422c-9012-4fbd-f0e3-f46982238596"
   },
   "outputs": [],
   "source": [
    "red_channel = image[:, :, 0]    # Red channel\n",
    "green_channel = image[:, :, 1]  # Green channel\n",
    "blue_channel = image[:, :, 2]   # Blue channel\n",
    "\n",
    "# Display the intensities of each channel (as numpy arrays)\n",
    "print(\"Blue Channel:\")\n",
    "print(blue_channel)\n",
    "\n",
    "print(\"Green Channel:\")\n",
    "print(green_channel)\n",
    "\n",
    "print(\"Red Channel:\")\n",
    "print(red_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wD_X6qHwHek0"
   },
   "source": [
    "### 3. Retomando con el ejercicio 1, analizar la imagen cargada ¿Existe algún problema con los colores mostrados con respecto a la imagen original?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tj81NLhRHmsE"
   },
   "source": [
    "Sí, los valores de los colores rojo y azul parecen estar intercambiados. Esto ocurre porque opencv interpreta las imágenes en BGR en lugar de RGB.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QW6ls_7H_Ar"
   },
   "source": [
    "### 4. Cargar la imagen pero antes de mostrarla utilizar el comando cvtColor(). ¿Que sucede ahora?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 703
    },
    "id": "zdtMmiKjIBl3",
    "outputId": "4736599a-2634-4172-e5ae-0d0ee39418aa"
   },
   "outputs": [],
   "source": [
    "# Convert the image from BGR to RGB\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "red_channel = image[:, :, 0]    # Red channel\n",
    "green_channel = image[:, :, 1]  # Green channel\n",
    "blue_channel = image[:, :, 2]   # Blue channel\n",
    "\n",
    "# Display the intensities of each channel (as numpy arrays)\n",
    "print(\"Blue Channel:\")\n",
    "print(blue_channel)\n",
    "\n",
    "print(\"Green Channel:\")\n",
    "print(green_channel)\n",
    "\n",
    "print(\"Red Channel:\")\n",
    "print(red_channel)\n",
    "\n",
    "show_image(\"CVT color\", image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_k7MA72nIQ7J"
   },
   "source": [
    "Los valores impresos por pantalla ahora se muestran correctamente porque cambiamos el formato de BGR a RGB. Sin embargo, cuando mostramos la imagen opencv espera que los colores estén en BGR y se ven los colores rojo y azul invertidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7nQZvCEShNa"
   },
   "source": [
    "### 5. Utilizar la función split() para una imagen RGB y separar en canales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 747
    },
    "id": "LsjaBwIdSiov",
    "outputId": "fa263fbf-e2f0-4e9a-912d-17b2f3d80560"
   },
   "outputs": [],
   "source": [
    "# Get the color channels\n",
    "red_channel, green_channel, blue_channel = cv2.split(image)\n",
    "\n",
    "# Show the individual channels\n",
    "show_image('Red Channel', red_channel)\n",
    "show_image('Green Channel', green_channel)\n",
    "show_image('Blue Channel', blue_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7J3w2l5TCi9"
   },
   "source": [
    "### 6. (*) La conversión de una imagen de color a escala de grises se puede hacer de varias formas. El ejercicio consiste en convertir la imagen de Lenna color a escala de grises utilizando diferentes metodos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149
    },
    "id": "Qoe6j-R8ZFqC",
    "outputId": "2c7c78cb-e213-4ae3-bddd-1eb574141178"
   },
   "outputs": [],
   "source": [
    "image = read_image( \"Lenna.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSheXt0GTGwf"
   },
   "source": [
    "#### a. Usando la libreria cv2 y el metodo cvtColor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "id": "Y6Po0_krTB9n",
    "outputId": "a78fab21-71f9-411a-9d2a-c48ad5086898"
   },
   "outputs": [],
   "source": [
    "# Parse to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "show_image(\"Grayscale\", gray_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhXbWdo-ThSs"
   },
   "source": [
    "#### b. Usando la fórmula de luminancia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "4cQLkVeLUlrQ",
    "outputId": "7985d94c-f9d7-4739-e5d4-ea0b857de51d"
   },
   "outputs": [],
   "source": [
    "red_channel, green_channel, blue_channel = cv2.split(image)\n",
    "\n",
    "# Calculate the luminance using the formula\n",
    "# Y = 0.299 * R + 0.587 * G + 0.114 * B\n",
    "luminance = 0.299 * red_channel + 0.587 * green_channel + 0.114 * blue_channel\n",
    "\n",
    "# Convert the luminance to uint8\n",
    "luminance = np.clip(luminance, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Show the luminance image\n",
    "show_image('Luminance Image', luminance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjrYfTFeVZL5"
   },
   "source": [
    "#### c. Usando scickit-image y el método rgb2gray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V5Za9PD4VlvD"
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "TriARoSMVm-t",
    "outputId": "6e103da5-e203-4644-c2eb-f574a75e85af"
   },
   "outputs": [],
   "source": [
    "# Convert the image from RGB to grayscale\n",
    "image_gray = rgb2gray(image)\n",
    "show_image(\"Grayscale\", image_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bSHsoujV_IT"
   },
   "source": [
    "#### d. ¿Qué pasa con los canales?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-ft3oWsWCCS"
   },
   "source": [
    "Ahora las imágenes solo tienen un único canal que corresponde, a la intensidad del blanco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQj798FBWfbO"
   },
   "source": [
    "#### e.  ¿Qué profundidad de bits tiene la imagen?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3wFTDTDWjM3"
   },
   "outputs": [],
   "source": [
    "def get_bit_depth(image):\n",
    "  # Get bit depth\n",
    "  dtype = image.dtype\n",
    "  bit_depth = 0\n",
    "\n",
    "  if dtype == np.uint8:\n",
    "    bit_depth = 8\n",
    "  elif dtype == np.uint16:\n",
    "    bit_depth = 16\n",
    "  elif dtype == np.float32:\n",
    "    bit_depth = 32\n",
    "\n",
    "  return bit_depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9vdKyVdxW1YH",
    "outputId": "0b639214-57eb-4268-be76-9c7f80ab1b52"
   },
   "outputs": [],
   "source": [
    "# Print bit depth\n",
    "print(\"Bit depth of the image:\", get_bit_depth(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1lY0FZPXoSA"
   },
   "source": [
    "#### f. Evaluar con otra imagen de mayor profundidad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "n6z3NnVXXrFw",
    "outputId": "ff82b07b-d337-4e9a-ed35-956db08aeba0"
   },
   "outputs": [],
   "source": [
    "image_16_bits = read_image( \"16_bits.png\")\n",
    "\n",
    "print(\"Bit depth of the image:\", get_bit_depth(image_16_bits))\n",
    "\n",
    "show_image(\"16 bit image\", image_16_bits)\n",
    "\n",
    "grayscale_16_bits = cv2.cvtColor(image_16_bits, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "show_image(\"Grayscale 16 bits\", grayscale_16_bits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaCbiVncZXBO"
   },
   "source": [
    "#### g. ¿Qué sucede con la imagen? ¿Ha cambiado algo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsKLmc78ZcQt"
   },
   "source": [
    "Al ojo humano, parece no haber diferencia entre una profundidad de bits de 8 y una de 16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TM8bP4yZjtK"
   },
   "source": [
    "### 7.  (*) Convertir la imagen de Lenna a otros modos de color, como CMYK, HSV, HSL. Mostrar el resultado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "id": "CvjjEA_RZnMe",
    "outputId": "aa141807-b7cf-45ce-e731-9fa95b91f96e"
   },
   "outputs": [],
   "source": [
    "# Convert from BGR to HSV (Hue, Saturation, Value)\n",
    "image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "show_image(\"HSV\", image_hsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "D7ZmrIa0ZuoH",
    "outputId": "ebb0b4fe-c12e-4fca-fa62-0e3c373c5568"
   },
   "outputs": [],
   "source": [
    "# Convert from BGR to HSL (Hue, Saturation, Lightness)\n",
    "image_hsl = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "show_image(\"HSL\", image_hsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "QhXd9nsXZ_UM",
    "outputId": "d6ec7082-24b7-401b-a031-ba4bb563ebaf"
   },
   "outputs": [],
   "source": [
    "# Convert from BGR to CMYK\n",
    "# OpenCV doesn't directly support CMYK, so we'll need to convert it manually\n",
    "image_cmyk = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB first\n",
    "image_cmyk = 255 - image_cmyk  # In CMYK, we subtract RGB values from 255\n",
    "show_image(\"CMYK\", image_cmyk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEs4JubracqN"
   },
   "source": [
    "### 8. (*) Tomar la imagen convertida en escala de grises y volver a convertir al en modo RGB. ¿Qué ha sucedido?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mhJsrnSwa3eX"
   },
   "outputs": [],
   "source": [
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "2fsqH0tlaeUd",
    "outputId": "2aac70a8-c497-473d-a8e8-d4314243732b"
   },
   "outputs": [],
   "source": [
    "# Convert back to grb\n",
    "image_color = cv2.cvtColor(gray_image, cv2.COLOR_GRAY2BGR)\n",
    "show_image(\"RGB image\", image_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXq3JPHdbDUz"
   },
   "source": [
    "Cuando se convirtió a escala de grises, se perdió información respectiva a la intensidad de cada color. Cuando volvemos a convertir a RGB, se aplica la misma información  a todos los canales, perdiendo toda diferencia entre intensidad de colores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oq9DVMxrbPpR"
   },
   "source": [
    "### 9. Cargar una imagen en color con OpenCV. Extrae los valores de un píxel en la posición (x, y). Modifica un área de la imagen (por ejemplo, convierte una región a rojo puro). Divide la imagen en sus tres canales de color (B, G, R) y muestra cada uno por separado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "j2Nz000HbULv",
    "outputId": "996c5970-d69c-4b56-c865-e156600adf8c"
   },
   "outputs": [],
   "source": [
    "# Modify a region of the image to pure red (BGR format for red is [0, 0, 255])\n",
    "top_left = (50, 50)\n",
    "size_x = 50\n",
    "size_y = 50\n",
    "bottom_right = (top_left[0] + size_x, top_left[1] + size_y)\n",
    "\n",
    "# Change the region to red by setting all pixel values in the region to pure red\n",
    "modified_image = image.copy()\n",
    "modified_image[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]] = [0, 0, 255]\n",
    "\n",
    "show_image(\"modified image\", modified_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "VD67uSgsb2bt",
    "outputId": "edde08ad-b3a0-4b01-927e-a1354f2c40af"
   },
   "outputs": [],
   "source": [
    "# Blue channel image (only blue channel visible, others set to 0)\n",
    "blue_image = image.copy()\n",
    "blue_image[:, :, 1] = 0  # Set the Green channel to 0\n",
    "blue_image[:, :, 2] = 0  # Set the Red channel to 0\n",
    "show_image(\"Blue image\", blue_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "5z-JiSLIcG9j",
    "outputId": "7eaba040-cbf2-4b01-a893-750bbf22c975"
   },
   "outputs": [],
   "source": [
    "# Green channel image (only green channel visible, others set to 0)\n",
    "green_image = image.copy()\n",
    "green_image[:, :, 0] = 0  # Set the Blue channel to 0\n",
    "green_image[:, :, 2] = 0  # Set the Red channel to 0\n",
    "show_image(\"Green image\", green_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "Z3J0dlrIcJ9p",
    "outputId": "5c4ba64d-2d07-4841-c62d-a97f422c227b"
   },
   "outputs": [],
   "source": [
    "# Red channel image (only red channel visible, others set to 0)\n",
    "red_image = image.copy()\n",
    "red_image[:, :, 0] = 0  # Set the Blue channel to 0\n",
    "red_image[:, :, 1] = 0  # Set the Green channel to 0\n",
    "show_image(\"Red image\", red_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znmB-dPkltuQ"
   },
   "source": [
    "# Sección 2\n",
    "## 6) (*) Implementar un modelo de compresión basado en codificación Run-Length Encoding (RLE). El algoritmo Run-Length Encoding (RLE) reduce el tamaño de una imagen representando secuencias consecutivas de píxeles idénticos como una sola entrada. Para ello convertir una imagen en escala de grises. luego, implementar el algoritmo RLE para comprimir la imagen. Posteriormente, implementar una función para descomprimir la imagen. Al finalizar, mostrar la imagen original y la imagen reconstruida. Probar con dos o tres imagenes que tengan diferentes características, modos de color. utilizar alguna de las metricas nombradas anteriormente e evaluar el resultado de la misma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DjDLvAwlrQLH",
    "outputId": "be941e6e-1001-433d-a2e2-445d8598143f"
   },
   "outputs": [],
   "source": [
    "def run_length_enconde(img):\n",
    "  encoded_img = []\n",
    "\n",
    "  # First we iterate the image\n",
    "  for row in range(img.shape[0]):\n",
    "    encoded_img_row = []\n",
    "    previous_pixel_value = img[row, 0]\n",
    "    count = 0\n",
    "    for col in range(img.shape[1]):\n",
    "        pixel_value = img[row, col]\n",
    "        if pixel_value == previous_pixel_value:\n",
    "            count += 1\n",
    "\n",
    "        else:\n",
    "          encoded_img_row.append((previous_pixel_value, count))\n",
    "          count = 1\n",
    "\n",
    "        previous_pixel_value = pixel_value\n",
    "    # This fixes bug of not appending last value\n",
    "    encoded_img_row.append((previous_pixel_value, count))\n",
    "    # Appends row\n",
    "    encoded_img.append(encoded_img_row)\n",
    "  return encoded_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_length_decode(img):\n",
    "  decoded_img = []\n",
    "  for row in range(len(img)):\n",
    "    decoded_img_row = []\n",
    "    for pixel_value, count in img[row]:\n",
    "      for _ in range(count):\n",
    "        decoded_img_row.append(pixel_value)\n",
    "\n",
    "    decoded_img.append(decoded_img_row)\n",
    "  return np.array(decoded_img, dtype=np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = read_image( \"Lenna.png\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "encoded_image = run_length_enconde(gray_image)\n",
    "decoded_image = run_length_decode(encoded_image)\n",
    "\n",
    "show_image(\"Original\", image)\n",
    "show_image(\"Grayscale\", gray_image)\n",
    "show_image(\"Decoded image\", decoded_image)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
